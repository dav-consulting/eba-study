
# Background and literature


NLP methods, developed within the field of computational linguistics, have grown increasingly popular during recent years due to their applicability to a variety of labor intensive and analytical tasks ranging from document summarization to sentiment classification. These methods are also being applied to other areas of research. For example, in finance, text from financial news, social media, and company filings have been used to predict asset price movements and study the causal impact of new information (Tetlock, 2007).

In macroeconomics, unstructured text has been used to forecast variation in inflation and unemployment and also estimate the effects of policy uncertainty (Scott and Varian, 2015). In media economics, similar texts from news and social media have been used to study the drivers and effects of political slant (Gentzkow and Shapiro, 2010). NLP methods have also been used in text analysis using speech as a metric of differences in partisan language between groups. For example, Lauderdale and Herzog (2016) used these methods to quantify political polarization by extracting features from speeches given in the U.S. Senate from 1995 to 2014, where they found that party differences in speech have increased faster than party differences in roll-call voting. Likewise, partisanship has recently been measured using the predictive accuracy of several machine-learning algorithms reaching similar conclusions with respect to increasing polarization (see Peterson and Spirling (2018) and Gentzkow, Shapiro and Taddy (2019)).

A recent state-of-the-art review of the existing and future applications for economic and political research can be found in Gentzkow et al. (2019). These methods have also been used for conducting systematic reviews. The idea here is that technologies and methods for NLP have the potential to speed up the production of systematic reviews by reducing the amount of manual labour needed and hence to an extent partially automate the process. ​Marshall and Wallace (2019) provide an overview of current machine learning methods that have been proposed to expedite evidence synthes​is, including their strengths and weaknesses, and how a systematic review team might go about using them in practice. They conclude that research into machine learning for systematic reviews has begun to mature, but many barriers to its practical use remain and that systematic reviews require very high accuracy in their methods, which may be difficult for automation to attain. Further, in areas with a high degree of subjectivity, it is also pointed out that readers are more likely to be reassured by the subjective but considered opinion of an expert human versus a machine. 

The field of international development cooperation also has its fair share of cases where new ways to conduct research, meta evaluations and systematic reviews are being tested and explored. OECD/DAC presented a working paper in 2019 that outlines that both the OECD and the World Bank are applying machine learning on a range of areas, such as topic modeling for classification of reports, tracking migration flows, and applying poverty prediction models. The working paper per se focused on using unsupervised machine learning to predict how international donors target the sustainable development goals (SDGs) with their projects (Pincet et al., 2019).

Another central actor in this field is the UN Global Pulse, which is an UN initiative that works with and supports projects with focus on big data and artificial intelligence for development, humanitarian action and peace. Projects such as making Ugandan community radio machines readable using speech recognition which is a collaboration project between UN global pulse, the Makerere University and Stellenbosch University constitutes a good example of where novel methods for how to process and utilize unstructured data. There are also recent studies that look into the possibility to bring in data science methods into the realm of evaluations of international development cooperation in order to improve the quality and reduce the time and costs of evaluations (see York and Bamberger 2020 or Petersson et al. 2017).

Other endeavors that have received attention uses high tech installations for data collection and analysis, for example using remote sensing and satellite imagery to improve response to humanitarian situations (Logar et al. 2020), or mobile network data as a way to inform policy making, in this case using data on how people live and move in the planning of health facilities constructions (Knippenberg et al. 2019). By and large, a clear momentum has been seen during recent years and the appetite for using such approaches seem to go hand in hand with the improved performance in many of these technologies. 


## Requirements an general skillset needed

The requirements, and general skillset, needed for a study of this sort can be boiled down to capacity in three separate fields - computer science and/or programming; mathematics and/or statistics; as well as contextual knowledge (Grus 2017). The computer science and programming aspects relate to knowledge about computers and computational software systems. In this study a wide range of [open source packages](#open-source-packages) have been utilized. The value of these packages cannot be understated in the development of strategies similar to the ones that has been applied in this study. Many of the packages used has taken many years to develop by large development teams. The open source packages and their utility varies from basic data environmental support, to data management and computational support as well as visualization of output. Database knowledge is also something that is required in order to store and run these kinds of systems. Requirements relating to mathematics and statistics are mostly tied to linear algebra, probability theory and inferential statistics. A final but important knowledge-based requirement is that of contextual knowledge which boils down to intuition of the context at hand. Such understanding of the fabric behind the numbers and patterns that are produced by the designed methods is very useful. In this study this translates to context knowledge and understanding of international development cooperation in general and the practice of evaluations in particular.

On top of the mentioned knowledge-based requirements, it is also important to emphasize that a machine-based approach, as most analytical approaches, requires time and devotion to be optimized in order to reach full potential. Rules-based approaches and pre-trained models takes less time to set-up and can be deployed without much preparations and pre-processing. In many cases a basic analytical structure can be set-up and produce robust analytical predictions in a matter of hours. However, in more complex cases where a specific model needs to be trained to get satisfactory results more resource are needed, and it is not unusual that entire teams spend years to optimize specific models. A central aspect that requires more resource when training models entails access to labelled training data (a source of truth further discussed in the method section). Training data can be secured either through secondary sources or through the process of [Natural language annotation](#other). This process refers to the generation of meta data or descriptive labels to underlying observations (or texts in the case of this study), and the purpose is to augment an algorithm's capability to give accurate predictions (Pustejovsky and Stubbs 2012). A final requirement that should not be forgotten is the importance of a constructive dialogue between the designer and the intended users of a machine-based approach. Understanding of the end-users needs and intended use-cases is crucial for establishing a practical and feasible machine-based approach.

